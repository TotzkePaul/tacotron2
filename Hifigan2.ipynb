{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tacotron 2 + Hifi-gan inference code \n",
    "Edit the variables **checkpoint_path** and **text** to match yours and run the entire code to generate plots of mel outputs, alignments and audio synthesis from the generated mel-spectrogram using Griffin-Lim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "sys.path.append('waveglow/')\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from hparams import create_hparams\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "from text import text_to_sequence\n",
    "from denoiser import Denoiser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hparams = create_hparams()\n",
    "hparams.sampling_rate = 22050\n",
    "hparams.max_decoder_steps = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import re\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "checkpoints = ['56500','60000', '60500', '63000']\n",
    "checkpoints = [ '84000']\n",
    "waveglows = ['400000']\n",
    "\n",
    "speakers = [('da_checkpoint_824800_done', 'da_waveglow_1516200'), ('jej_checkpoint_904500_done', 'jej_waveglow890k_done')]\n",
    "speakers = [('jej_checkpoint_904500_done', 'jej_waveglow890k_done')]\n",
    "settings_groups = [('a', 0.02, 0.666)]\n",
    "texts = []\n",
    "\n",
    "text_file = open(\"../Samples/Work.txt\", \"r\", encoding=\"utf8\")\n",
    "texts = text_file.readlines()\n",
    "for speaker in speakers:\n",
    "    checkpoint = speaker[0]\n",
    "    wg = speaker[1]\n",
    "    checkpoint_path = \"../Models/\"+ speaker[0]\n",
    "    model = load_model(hparams)\n",
    "    model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "    _ = model.cuda().eval().half()\n",
    "    waveglow_path = '../Models/'+speaker[1]\n",
    "    waveglow = torch.load(waveglow_path)['model']\n",
    "    waveglow.cuda().eval().half()\n",
    "    for k in waveglow.convinv:\n",
    "        k.float()\n",
    "    denoiser = Denoiser(waveglow)\n",
    "    for index, text in enumerate(texts):\n",
    "        for settings in settings_groups:\n",
    "            sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "            sequence = torch.autograd.Variable(\n",
    "                torch.from_numpy(sequence)).cuda().long()\n",
    "            mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "            mel_postnet = mel_outputs_postnet.detach().cpu().numpy()\n",
    "            \n",
    "            output_dir = '../Samples/mel_outputs_postnet/'\n",
    "\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            filename = output_dir+'{0:03d}'.format(index)+'_'+checkpoint+\"_wg\"+wg+'_'+re.sub(r'\\W+', '', text)[:30]+'_'+settings[0]+'.npy'\n",
    "            #audio.export(filename, format=\"wav\")\n",
    "            np.save(filename, mel_postnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\deepfakes\\tacotron2-Offerman\\hifi-gan\n"
     ]
    }
   ],
   "source": [
    "%cd hifi-gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Inference Process..\n",
      "Loading './pretrained/LJ_FT_T2_V1/generator_v1'\n",
      "Complete.\n",
      "Removing weight norm...\n",
      "../../Samples/hifi-gan_outputs/000_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Twasthenightbeforecoowedfreeze_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/001_jej_checkpoint_904500_done_wgjej_waveglow890k_done_notaprogramwasworkingnoteventh_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/002_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Theprogrammershungbytheirlapto_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/003_jej_checkpoint_904500_done_wgjej_waveglow890k_done_withhopesthatamiraclesoonwould_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/004_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Theuserswerenestledallsnuginth_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/005_jej_checkpoint_904500_done_wgjej_waveglow890k_done_whilevisionsofinquiriesdancedi_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/006_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Whenoutinthemuhsheenroomtherea_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/007_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Isprangfrommydesktoseewhatwast_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/008_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Andwhattowonderingeyesshouldap_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/009_jej_checkpoint_904500_done_wgjej_waveglow890k_done_butJakeNoisewithasixpackofbeer_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/010_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Hisrezumeiglowedwithexperience_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/011_jej_checkpoint_904500_done_wgjej_waveglow890k_done_heturnedoutgreatcodewithanengi_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/012_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Morerapidthanfiberhiskeystroke_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/013_jej_checkpoint_904500_done_wgjej_waveglow890k_done_andhecursedandmutteredandcalle_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/014_jej_checkpoint_904500_done_wgjej_waveglow890k_done_getfetchgetpullgetpush_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/015_jej_checkpoint_904500_done_wgjej_waveglow890k_done_getcodereviewedgitPeeAreComple_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/016_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Hiseyeswereglassedoverfingersn_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/017_jej_checkpoint_904500_done_wgjej_waveglow890k_done_fromweekendsandnightsinfrontof_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/018_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Awinkofhiseyeandatwitchofhishe_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/019_jej_checkpoint_904500_done_wgjej_waveglow890k_done_soongavemetoknowIhadnothingtod_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/020_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Hespokenotawordbutwentstraight_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/021_jej_checkpoint_904500_done_wgjej_waveglow890k_done_turningspecsintocodethenturned_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/022_jej_checkpoint_904500_done_wgjej_waveglow890k_done_AndlayinghisfingerupontheENTER_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/023_jej_checkpoint_904500_done_wgjej_waveglow890k_done_thesystemcameupandworkdperfect_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/024_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Theupdatedupdatedthedeletesthe_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/025_jej_checkpoint_904500_done_wgjej_waveglow890k_done_theinquiriesinquiredtheclosing_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/026_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Hetestedeachwhistleandtestedea_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/027_jej_checkpoint_904500_done_wgjej_waveglow890k_done_withnaryabugandallhadgonewell_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/028_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Thesystemwasfinishedthetestswe_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/029_jej_checkpoint_904500_done_wgjej_waveglow890k_done_theuserslastchangeswereeveninc_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/030_jej_checkpoint_904500_done_wgjej_waveglow890k_done_Andtheuserexclaimedwithsnarlan_a_generated_e2e.wav\n",
      "../../Samples/hifi-gan_outputs/031_jej_checkpoint_904500_done_wgjej_waveglow890k_done_ItsjustwhatIaskedfourbutnotwha_a_generated_e2e.wav\n"
     ]
    }
   ],
   "source": [
    "!python inference_e2e.py --input_mels_dir \"../../Samples/mel_outputs_postnet/\"  --output_dir \"../../Samples/hifi-gan_outputs/\" --checkpoint_file \"./pretrained/VCTK_V1/generator_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-inf]",
   "language": "python",
   "name": "conda-env-.conda-inf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
